# SkillPilot Migration Guide: From Pseudo to Production

## Overview

This guide explains how to migrate from the pseudo environment (no real Innovus/dsub) to a real production environment with actual Cadence Innovus and dsub.

---

## Architecture Differences

### Pseudo Environment (Current)
- **Adapter**: `PseudoSupervisor` + `PseudoSession`
- **Execution**: Python subprocess simulating Innovus queue_processor
- **Session**: Python thread, not actual Innovus process
- **Scripts**: TCL files generated but not really executed
- **Reports**: Generated by PseudoSession based on contract

### Production Environment
- **Adapter**: `SupervisorDsubI` (new)
- **Execution**: Real Innovus no_gui process via `dsub -I`
- **Session**: Actual Innovus process
- **Scripts**: TCL files executed by real Innovus
- **Reports**: Generated by real skill TCL scripts

---

## Step-by-Step Migration

### Step 1: Implement `SupervisorDsubI` Adapter

Create a new adapter file: `skillpilot/adapters/dsub_i.py`

```python
"""
Production adapter for dsub -I + Innovus
"""

import json
import os
import subprocess
import time
from pathlib import Path
from typing import Optional, Dict, Any
from dataclasses import dataclass
from skillpilot.protocol.schema import SCHEMA_VERSION


@dataclass
class SessionHandle:
    """Handle for a production Innovus session"""
    pid: int
    run_dir: Path
    dsub_command: str
    stop_requested: bool = False


class SupervisorDsubI:
    """Production supervisor - uses dsub -I to start Innovus"""

    def __init__(self, dsub_config: Optional[Dict[str, Any]] = None):
        self.dsub_config = dsub_config or self._default_dsub_config()
        self.sessions: Dict[str, SessionHandle] = {}

    def _default_dsub_config(self) -> Dict[str, Any]:
        """Default dsub configuration"""
        return {
            "queue": "default",
            "walltime": "1:00:00",
            "nodes": "1",
            "cores": "1",
            "memory": "8G",
            "license": "innovus",
        }

    def start(self, run_dir: Path, env: dict) -> SessionHandle:
        """Start Innovus session via dsub -I"""
        session_dir = run_dir / "session"
        session_dir.mkdir(parents=True, exist_ok=True)
        
        # Build dsub command
        dsub_cmd = self._build_dsub_command(run_dir)
        
        # Create supervisor log
        supervisor_log = session_dir / "supervisor.log"
        with open(supervisor_log, "w") as f:
            f.write(f"SupervisorDsubI: Starting Innovus session\n")
            f.write(f"run_dir: {run_dir}\n")
            f.write(f"dsub command: {dsub_cmd}\n")
        
        # Start Innovus process
        stdout_log = session_dir / "innovus.stdout.log"
        stderr_log = session_dir / "innovus.stderr.log"
        
        with open(stdout_log, "w") as stdout_f, open(stderr_log, "w") as stderr_f:
            process = subprocess.Popen(
                dsub_cmd,
                stdout=stdout_f,
                stderr=stderr_f,
                env=env,
            )
        
        # Create initial state
        state = {
            "schema_version": SCHEMA_VERSION,
            "pid": process.pid,
            "start_time": time.time(),
            "exit_code": None,
            "last_heartbeat_ts": None,
            "dsub_command": dsub_cmd,
        }
        state_path = session_dir / "state.json"
        with open(state_path, "w") as f:
            json.dump(state, f, indent=2)
        
        handle = SessionHandle(
            pid=process.pid,
            run_dir=run_dir,
            dsub_command=dsub_cmd,
        )
        self.sessions[str(run_dir)] = handle
        return handle

    def _build_dsub_command(self, run_dir: Path) -> list:
        """Build dsub -I command"""
        # Bootstrap script path
        bootstrap = run_dir / "scripts" / "bootstrap.tcl"
        
        # Build command (adjust based on your dsub implementation)
        cmd = [
            "dsub", "-I",
            "-q", self.dsub_config["queue"],
            "-W", self.dsub_config["walltime"],
            "--",
            "innovus", "-no_gui", "-init", str(bootstrap),
        ]
        
        return cmd

    def wait_ready(self, handle: SessionHandle, timeout_s: int = 60) -> bool:
        """Wait for Innovus to be ready"""
        ready_file = handle.run_dir / "session" / "ready"
        heartbeat_file = handle.run_dir / "session" / "heartbeat"
        
        start = time.time()
        while time.time() - start < timeout_s:
            # Check for ready file
            if ready_file.exists():
                return True
            
            # Or check for heartbeat
            if heartbeat_file.exists():
                heartbeat_time = heartbeat_file.stat().st_mtime
                if time.time() - heartbeat_time < 10:
                    return True
            
            time.sleep(0.5)
        
        return False

    def stop(self, handle: SessionHandle, reason: str = "") -> None:
        """Stop Innovus session"""
        # Send SIGTERM
        try:
            os.kill(handle.pid, 15)  # SIGTERM
        except ProcessLookupError:
            pass  # Process already dead
        
        handle.stop_requested = True
        
        # Write stop reason
        stop_file = handle.run_dir / "session" / "stop"
        with open(stop_file, "w") as f:
            f.write(reason or "stopped_by_supervisor")

    def poll_health(self, handle: SessionHandle) -> Dict[str, Any]:
        """Poll Innovus session health"""
        session_dir = handle.run_dir / "session"
        heartbeat_file = session_dir / "heartbeat"
        state_file = session_dir / "state.json"
        
        result = {
            "status": "healthy",
            "heartbeat_age_s": 0,
            "last_heartbeat_ts": None,
        }
        
        # Check if process is still running
        try:
            os.kill(handle.pid, 0)  # Signal 0 just checks if process exists
        except ProcessLookupError:
            result["status"] = "crashed"
            return result
        
        # Check heartbeat
        if heartbeat_file.exists():
            heartbeat_time = heartbeat_file.stat().st_mtime
            result["last_heartbeat_ts"] = heartbeat_time
            result["heartbeat_age_s"] = time.time() - heartbeat_time
        else:
            result["status"] = "no_heartbeat"
            return result
        
        # Check if heartbeat is stale
        if result["heartbeat_age_s"] > 60:
            result["status"] = "heartbeat_lost"
        
        # Check state
        if state_file.exists():
            with open(state_file, "r") as f:
                state = json.load(f)
            if state.get("exit_code") is not None:
                result["status"] = "crashed" if state["exit_code"] != 0 else "exited"
        
        return result

    def collect_logs(self, handle: SessionHandle) -> None:
        """Ensure logs are collected"""
        # Logs are already collected by redirecting stdout/stderr
        pass
```

---

### Step 2: Implement Real `bootstrap.tcl`

Create `skillpilot/kernel/bootstrap.tcl.template`:

```tcl
# bootstrap.tcl
# Innovus queue_processor bootstrap script
# Generated by SkillPilot

puts "SkillPilot: Starting queue_processor..."

# Configuration
set ::SP_RUN_DIR "<RUN_DIR>"
set ::SP_SCRIPTS_DIR [file join $::SP_RUN_DIR "scripts"]
set ::SP_QUEUE_DIR [file join $::SP_RUN_DIR "queue"]
set ::SP_ACK_DIR [file join $::SP_RUN_DIR "ack"]
set ::SP_REPORTS_DIR [file join $::SP_RUN_DIR "reports"]

# Write ready signal
set ready_file [file join $::SP_RUN_DIR "session" "ready"]
set fp [open $ready_file w]
puts $fp "ready"
close $fp

# Main queue processing loop
proc update_heartbeat {} {
    global ::SP_RUN_DIR
    set heartbeat_file [file join $::SP_RUN_DIR "session" "heartbeat"]
    set fp [open $heartbeat_file w]
    puts $fp "[clock seconds]"
    close $fp
}

proc process_queue {} {
    global ::SP_RUN_DIR ::SP_SCRIPTS_DIR ::SP_QUEUE_DIR ::SP_ACK_DIR
    
    # Check for stop signal
    set stop_file [file join $::SP_RUN_DIR "session" "stop"]
    if {[file exists $stop_file]} {
        return 0
    }
    
    # Process queue files
    foreach queue_file [glob -nocomplain [file join $::SP_QUEUE_DIR "*.json"]] {
        set request_id [file tail [file rootname $queue_file]]
        
        # Check if ack already exists
        set ack_file [file join $::SP_ACK_DIR "${request_id}.json"]
        if {[file exists $ack_file]} {
            continue
        }
        
        # Read request
        set fp [open $queue_file r]
        set request_json [read $fp]
        close $fp
        
        # Parse JSON (TCL's json package or custom parser)
        set script ""
        catch {
            set request [parse_json $request_json]
            set script [dict get $request "script"]
        }
        
        if {$script eq ""} {
            continue
        }
        
        # Security check
        if {![string match "scripts/*" $script]} {
            set ack_json [create_fail_ack $request_id "CMD_FAIL" "Security violation"]
            write_ack $ack_file $ack_json
            continue
        }
        
        if {[string first ".." $script] >= 0} {
            set ack_json [create_fail_ack $request_id "CMD_FAIL" "Security violation"]
            write_ack $ack_file $ack_json
            continue
        }
        
        # Execute script
        set script_path [file join $::SP_RUN_DIR $script]
        set start_time [clock milliseconds]
        
        set status "PASS"
        set error_type "OK"
        set message ""
        
        if {[catch {source $script_path} error]} {
            set status "FAIL"
            if {[string match "*restore_wrapper*" $script]} {
                set error_type "RESTORE_FAIL"
            } else {
                set error_type "CMD_FAIL"
            }
            set message $error
        }
        
        set end_time [clock milliseconds]
        set duration [expr {$end_time - $start_time}]
        
        # Write ack
        set ack_json [create_ack $request_id $status $error_type $message $start_time $end_time]
        write_ack $ack_file $ack_json
    }
    
    return 1
}

proc create_ack {request_id status error_type message start_time end_time} {
    # Create ack JSON (simplified)
    return "..."
}

proc create_fail_ack {request_id error_type message} {
    # Create fail ack JSON (simplified)
    return "..."
}

proc write_ack {ack_file ack_json} {
    # Write ack atomically
    set tmp_file "${ack_file}.tmp.[pid]"
    set fp [open $tmp_file w]
    puts $fp $ack_json
    close $fp
    file rename -force $tmp_file $ack_file
}

# Main loop
while {1} {
    update_heartbeat
    set keep_running [process_queue]
    if {!$keep_running} {
        break
    }
    after 100
}

puts "SkillPilot: queue_processor exiting"
```

---

### Step 3: Update `ExecutionKernel` to Generate Real Bootstrap

Update `skillpilot/kernel/__init__.py`:

```python
def write_bootstrap_tcl(self) -> Path:
    """Generate bootstrap.tcl for Innovus"""
    template_path = Path(__file__).parent / "bootstrap.tcl.template"
    with open(template_path, "r") as f:
        template = f.read()
    
    # Replace placeholders
    content = template.replace("<RUN_DIR>", str(self.run_dir))
    
    bootstrap_path = self.scripts_dir / "bootstrap.tcl"
    bootstrap_path.write_text(content)
    return bootstrap_path
```

---

### Step 4: Create Real Skill TCL Scripts

For each subskill, create real TCL scripts that work with Innovus.

Example: `subskills/summary_health/templates/run.tcl`

```tcl
# summary_health run script
# Real Innovus commands

puts "Running summary_health..."

# Get design info
set num_cells [getInstCount -filter {isHierarchical == 0}]
set utilization [utilization]

# Get timing info
set wnss [getAnalysisResult -max_wns]
set tnss [getAnalysisResult -max_wns_sum]

# Generate reports
set fp [open $::SP_REPORTS_DIR/summary_health.txt w]
puts $fp "Design Health Summary"
puts $fp "===================="
puts $fp "Overall Status: HEALTHY"
puts $fp "Total Cells: $num_cells"
puts $fp "Utilization: $utilization"
close $fp

set fp [open $::SP_REPORTS_DIR/timing_health.txt w]
puts $fp "Timing Health Report"
puts $fp "===================="
puts $fp "Setup WNS: $wnss"
puts $fp "Setup TNS: $tnss"
close $fp

puts "summary_health completed"
```

---

### Step 5: Update Orchestrator to Use Production Adapter

Add adapter selection logic:

```python
class Orchestrator:
    def __init__(self, cwd: Path, skill_root: Path, adapter: str = "pseudo"):
        self.cwd = cwd
        self.skill_root = skill_root
        self.adapter_type = adapter
        
        if adapter == "pseudo":
            self.supervisor = PseudoSupervisor()
        elif adapter == "dsub-i":
            from skillpilot.adapters.dsub_i import SupervisorDsubI
            self.supervisor = SupervisorDsubI()
        else:
            raise ValueError(f"Unknown adapter: {adapter}")
```

---

### Step 6: Create Production Configuration

Create `config/production.yaml`:

```yaml
adapter: "dsub-i"

dsub_config:
  queue: "innovus_q"
  walltime: "2:00:00"
  nodes: "1"
  cores: "4"
  memory: "16G"
  license: "innovus"

supervisor_config:
  ready_timeout_s: 60
  heartbeat_timeout_s: 120
  queue_timeout_s: 600

runtime_config:
  scan_depth: 3
```

---

## Testing Migration

### Phase 1: Test Environment Setup

1. Verify Innovus is available:
   ```bash
   which innovus
   innovus -version
   ```

2. Verify dsub is available:
   ```bash
   which dsub
   dsub --help
   ```

3. Test basic Innovus execution:
   ```bash
   echo "puts hello" | innovus -no_gui
   ```

### Phase 2: Test Bootstrap

1. Create minimal test run_dir:
   ```bash
   mkdir -p test_run/session test_run/scripts
   ```

2. Generate bootstrap.tcl
3. Run Innovus with bootstrap:
   ```bash
   innovus -no_gui -init test_run/scripts/bootstrap.tcl
   ```

4. Verify:
   - `test_run/session/ready` exists
   - `test_run/session/heartbeat` updates

### Phase 3: Test Request/Ack Loop

1. Create test request in `test_run/queue/`
2. Verify ack appears in `test_run/ack/`
3. Check ack status and error_type

### Phase 4: Run Full Job

```python
from skillpilot.orchestrator import Orchestrator
from pathlib import Path

orchestrator = Orchestrator(
    cwd=Path("/path/to/design"),
    skill_root=Path("/path/to/subskills"),
    adapter="dsub-i",  # Use production adapter
)

result = orchestrator.run_job(
    design_query="./my_block.enc",
    skill_name="summary_health",
)

print(f"Status: {result.status}")
print(f"Run dir: {result.run_dir}")
```

---

## Common Migration Issues

### Issue 1: Innovus Path Not Found

**Solution**: Add Innovus to PATH or specify full path in dsub config.

### Issue 2: License Not Available

**Solution**: Check license server, configure `FLEXLM_TIMEOUT` and `CDS_LIC_FILE`.

### Issue 3: Queue Submission Fails

**Solution**: Verify dsub configuration, queue exists, resource limits are appropriate.

### Issue 4: Session Ready Timeout

**Solution**: 
- Check Innovus startup time
- Increase `ready_timeout_s` in config
- Verify bootstrap.tcl has no syntax errors

### Issue 5: Heartbeat Timeout

**Solution**:
- Check if queue_processor is running
- Verify Innovus hasn't crashed
- Check system resources

---

## Production Deployment Checklist

- [ ] Innovus installed and licensed
- [ ] dsub installed and configured
- [ ] Queue configured with appropriate resources
- [ ] Bootstrap.tcl tested and working
- [ ] Real skill TCL scripts implemented
- [ ] All L2 integration tests passing
- [ ] Debug bundle generation verified
- [ ] Monitoring/alerting configured
- [ ] Log rotation configured
- [ ] Storage for run_dirs provisioned
- [ ] Backup strategy in place

---

## Next Steps

1. Implement `SupervisorDsubI` adapter
2. Create real `bootstrap.tcl`
3. Implement real skill TCL scripts
4. Add L2 integration tests
5. Deploy to staging environment
6. Run full regression
7. Deploy to production
